{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DiffusionGS"
      ],
      "metadata": {
        "id": "56DRLegJNp_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/pleasure97/3D-AI-ML-Code-Implementation/main/2025/DiffusionGS/assets/pipeline.JPG\" alt=\"Pipeline of DiffusionGS\">\n",
        "</div>"
      ],
      "metadata": {
        "id": "3c390lG2jlTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Training"
      ],
      "metadata": {
        "id": "pMV_h5QfCaiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 3D Diffusion\n",
        "---\n",
        "*  $\\mathbf{x}_{\\text {con }} \\in \\mathbb{R}^{H \\times W \\times 3}$ - 1 clean condition view\n",
        "* $\\mathcal{X}_t=\\left\\{\\mathbf{x}_t^{(1)}, \\mathrm{x}_t^{(2)}, \\cdots, \\mathbf{x}_t^{(N)}\\right\\}$ -  $N$ noisy views\n",
        "  * $\\mathcal{X}_0=\\left\\{\\mathbf{x}_0^{(1)}, \\mathrm{x}_0^{(2)}, \\cdots, \\mathrm{x}_0^{(\\mathrm{N})}\\right\\}$ - *Concatenated with $\\mathcal{X}_t$*\n",
        "* $\\mathbf{v}_{\\text {con }} \\in \\mathbb{R}^{H \\times W \\times 6}$\n",
        "  * $\\mathcal{V}=\\left\\{\\mathbf{v}^{(1)}, \\mathbf{v}^{(2)}, \\cdots, \\mathbf{v}^{(\\mathbb{N})}\\right\\}$\n",
        "\n",
        "$$\\mathbf{x}_t^{(i)}=\\overline{\\alpha_t} \\mathbf{x}_0^{(i)}+\\sqrt{1-\\overline{\\alpha_t}} \\epsilon_t^{(i)}$$\n",
        "* $\\overline{\\alpha_t}$ - pre-scheduled hyper-parameter\n",
        "* $\\epsilon_t^{(i)} \\sim \\mathcal{N}(0, \\mathbf{I})$ and $i=1,2, \\cdots, N$\n",
        "* $t$ - timestep\n",
        "---\n",
        "$$\\mathcal{G}_\\theta\\left(\\mathcal{X}_t \\mid \\mathbf{x}_{c o n}, \\mathbf{v}_{c o n}, t, \\mathcal{V}\\right)=\\left\\{G_t^{(k)}\\left(\\mu_t^{(k)}, \\boldsymbol{\\Sigma}_t^{(k)}, \\alpha_t^{(k)}, c_t^{(k)}\\right)\\right\\}$$\n",
        "* $\\theta$ - denoiser\n",
        "* $\\mathcal{G}_\\theta$ - predicted 3D Gaussians by $\\theta$\n",
        "* $1 \\leq k \\leq N_g$\n",
        "* $N_g=(N+1) H W$ - the number of per-pixel Gaussian $G_t^{(k)}$\n",
        "* $H , W$ - Height and Width of the image\n",
        "* $\\mu_t^{(k)} \\in$ $\\mathbb{R}^3$ - the center position of each $G_t^{(k)}$ (clipped into $[-1, 1]^3$)\n",
        "* $\\Sigma_t^{(k)} \\in \\mathbb{R}^{3 \\times 3}$ - the covariance of each $G_t^{(k)}$ controlling its shape\n",
        "  * parameterized by a rotation matrix $\\mathbf{R}_t^{(k)}$ and a scaling matrix $\\mathbf{S}_t^{(k)}$\n",
        "* $\\alpha_t^{(k)} \\in \\mathbb{R}$ - the opacity of each $G_t^{(k)}$ characterizing the transmittance\n",
        "* $c_t^{(k)} \\in \\mathbb{R}^3$ - the RGB color of each $G_t^{(k)}$\n",
        "---\n",
        "$$\\mu_t^{(k)}=o^{(k)}+u_t^{(k)} d^{(k)}$$\n",
        "* $o^{(k)}$ - the origin of the $k$-th pixel-aligned ray\n",
        "* $d^{(k)}$ - the direction of the $k$-th pixel-aligned ray\n",
        "---\n",
        "$$u_t^{(k)}=w_t^{(k)} u_{\\text {near }}+\\left(1-w_t^{(k)}\\right) u_{f a r}$$\n",
        "* $w_t^{(k)} \\in \\mathbb{R}$ - the weight to control $u_t^{(k)}$\n",
        "* $u_{\\text {near }}$ - the nearest distances\n",
        "* $u_{f a r}$ - the farthest distances\n",
        "* For the object-level Gaussian decoder, $[u_{\\text {near }}, u_{f a r}] = [0.1, 4.2]$\n",
        "* For the scene-level Gaussian decoder, $[u_{\\text {near }}, u_{f a r}] = [0, 500]$"
      ],
      "metadata": {
        "id": "qYITwRYUj0AR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Denoiser\n",
        "\n",
        "---\n",
        "\n",
        "* $L$ - the number of tranformer blocks\n",
        "* Each transformer block contains 1 MSA, 1 MLP, and 2 LN.\n",
        "* $\\hat{\\mathcal{H}}=\\left\\{\\hat{\\mathbf{H}}_{\\text {con }}, \\hat{\\mathbf{H}}^{(1)}, \\cdots, \\hat{\\mathbf{H}}^{(N)}\\right\\}$ - per-pixel Gaussian Maps\n",
        "  * $\\hat{\\mathbf{H}}_{\\text {con }}$, $\\hat{\\mathbf{H}}^{(i)} \\in$ $\\mathbb{R}^{H \\times W \\times 14}$\n",
        "---\n",
        "$$\\hat{\\mathcal{X}}_{(0, t)}=\\left\\{\\hat{\\mathbf{x}}_{(0, t)}^{(1)}, \\hat{\\mathbf{x}}_{(0, t)}^{(2)}, \\cdots, \\hat{\\mathbf{x}}_{(0, t)}^{(N)}\\right\\}$$\n",
        "* $\\hat{\\mathcal{X}}_{(0, t)}$ - the denoised multi-view images\n",
        "\n",
        "---\n",
        "$$\\hat{\\mathbf{x}}_{(0, t)}^{(i)}=F_r\\left(\\mathbf{M}_{e x t}^{(i)}, \\mathbf{M}_{i n t}^{(i)}, \\mathcal{G}_\\theta\\left(\\mathcal{X}_t \\mid \\mathbf{x}_{c o n}, \\mathbf{v}_{c o n}, t, \\mathcal{V}\\right)\\right)$$\n",
        "* $F_r$ - the differentiable rasterization function\n",
        "* $1 \\leq i \\leq N$\n",
        "* $\\mathbf{M}_{e x t}^{(i)}$ - the extrinsic matrix of the viewpoint $\\mathbf{c}^{(i)}$.\n",
        "* $\\mathbf{M}_{i n t}^{(i)}$ - the intrinsic matrix of the viewpoint $\\mathbf{c}^{(i)}$.\n",
        "\n",
        "---\n",
        "$$\\boldsymbol{\\Sigma}_t^{\\prime(k, i)}=\\mathbf{J}_t^{(i)} \\mathbf{W}_t^{(i)} \\boldsymbol{\\Sigma}_t^{(k)} \\mathbf{W}_t^{(i)^{\\top}} \\mathbf{J}_t^{(i)^{\\top}}$$\n",
        "* $\\boldsymbol{\\Sigma}_t^{(k)}$ - the 3D covariance matrix of each $G_t^{(k)}$ at viewpoint $\\mathbf{c}^{(i)}$ in the world coordinate system\n",
        "* $\\boldsymbol{\\Sigma}_t^{\\prime(k, i)} \\in \\mathbb{R}^{3 \\times 3}$  - the 3D covariance matrix of each $G_t^{(k)}$ at viewpoint $\\mathbf{c}^{(i)}$ in the camera coordinate system\n",
        "*  $\\mathbf{J}_t^{(i)} \\in \\mathbb{R}^{3 \\times 3}$ - the Jacobian matrix of the affine approximation of the projective transformation\n",
        "* $\\mathbf{W}_t^{(i)} \\in \\mathbb{R}^{3 \\times 3}$ - the viewing transformation"
      ],
      "metadata": {
        "id": "N7xysn6KpRyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Scene-Object Mixed Training Strategy\n",
        "\n",
        "---\n",
        "\n",
        "### Viewpoint Selecting\n",
        "\n",
        "$$\\theta_{c d}^{(i)} \\leq \\theta_1, \\quad \\theta_{d n}^{(i, j)} \\leq \\theta_2,$$\n",
        "\n",
        "* The first constraint of the angle between viewpoint and positions\n",
        "* $\\theta_{c d}^{(i)}$ - the angle between the $i$-th noisy view position and the condition view position\n",
        "* $\\theta_{d n}^{(i, j)}$ - the angle between the $i$-th noisy view position and the $j$-th novel view position\n",
        "* $\\theta_{1}, \\theta_{2}$ - hyperparamters\n",
        "* $1 \\leq i \\leq N$\n",
        "* $1 \\leq$ $j \\leq M$\n",
        "\n",
        "$$\n",
        "\\frac{\\vec{z}_{c o n} \\cdot \\vec{z}_{n o i s e}^{(i)}}{\\left|\\vec{z}_{\\text {con }}\\right| \\cdot\\left|\\vec{z}_{\\text {noise }}^{(i)}\\right|} \\geq \\cos \\left(\\varphi_1\\right), \\frac{\\vec{z}_{\\text {con }} \\cdot \\vec{z}_{n v}^{(j)}}{\\left|\\vec{z}_{\\text {con }}\\right| \\cdot\\left|\\vec{z}_{n v}^{(j)}\\right|} \\geq \\cos \\left(\\varphi_2\\right)\n",
        "$$\n",
        "\n",
        "* The second constraint of the angle between viewpoint orientations\n",
        "* $\\vec{z}_{c o n}$ - the forward direction vectors of the condition view\n",
        "* $\\vec{z}_{n o i s e}^{(i)}$ - the forward direction vectors of the $i$-th noisy view\n",
        "* $\\vec{z}_{n v}^{(j)}$ - the forward direction vectors of the $j$-th novel view\n",
        "* $\\varphi_1$, $\\varphi_2$ - hyperparameters\n",
        "\n",
        "---\n",
        "\n",
        "### Reference-Point PlÃ¼cker Coordinate (RPPC)\n",
        "\n",
        "$$r=(o-(o \\cdot d) d, d)$$\n",
        "\n",
        "* $r$ - the pixel-aligned ray embeddings\n",
        "* $o$ - the position of the ray landing on the pixel\n",
        "* $d$ - the direction of the ray landing on the pixel\n",
        "\n",
        "---\n",
        "\n",
        "### Overall Training Objective\n",
        "\n",
        "$$\\mathcal{L}_{\\text{pd}} = \\mathbb{E}_k \\left[ l_t^{(k)} - \\frac{\\mathbb{E}_k[l_t^{(k)}] - \\sigma_0 + \\mathbb{E}[o^{(k)}]}{\\sqrt{\\text{Var}(l_t^{(k)})}} \\right]$$\n",
        "\n",
        "* ${L}_{\\text{pd}}$ - the point distribution loss for training warm-up\n",
        "* $\\mathbb{E}$ - the mean value\n",
        "* $l_t^{(k)} = |u_t^{(k)} d^{(k)}|$\n",
        "* $Var$ - the variance\n",
        "* $\\sigma_{0}$ - the target standard deviation (set to 0.5)\n",
        "\n",
        "$$\\mathcal{L} = (\\mathcal{L}_{\\text{de}} + \\mathcal{L}_{\\text{nv}}) \\cdot \\mathbb{1}_{\\text{iter} > \\text{iter}_0} + \\mathcal{L}_{\\text{pd}} \\cdot \\mathbb{1}_{\\text{iter} \\leq \\text{iter}_0} \\cdot \\mathbb{1}_{\\text{object}}$$\n",
        "\n",
        "* $\\mathcal{L}$ - the overall training objective\n",
        "* $\\mathcal{L}_{\\text{nv}}$ - the novel view loss\n",
        "* $\\mathbb{1}_{\\text{iter} > \\text{iter}_0}$ - the conditional indicator function which equals 1 if the current training iteration is greater than the threshold $iter_{0}$\n",
        "* $\\mathbb{1}_{\\text{iter} > \\text{iter}_0}$  - similar indicator function as above\n"
      ],
      "metadata": {
        "id": "e1SFPNu3HG5s"
      }
    }
  ]
}