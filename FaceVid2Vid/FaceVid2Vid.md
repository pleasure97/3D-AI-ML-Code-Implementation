
## One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing  


### 논문의 연구 목적 
---
</br>

![](./img/Face-Vid2Vid-1.jpg)

</br>
</br>
&nbsp; 저자들은 카메라를 대놓고 말하는 사람에 대한 비디오를 바탕으로 deep neural network를 사용해 새로운 영상을 합성해내고자 한다. 합성하고자 하는 영상의 종류는 크게 다음과 같다. 

</br>

![](./img/Face-Vid2Vid-13.jpg)

</br>

&nbsp;  첫째, talking-head image synthesis이다. talking-head image synthesis는 주어진 원본 영상의 말하는 사람에 대한 정보를 바탕으로 머리 위치와 감정 표현을 합성해낸다. talking-head image synthesis는 same-identity reconstruction과 cross-identity motion transfer라는 하위 분야로 나뉜다.  same-identity reconstruction은 원본 영상의 말하는 사람의 머리 위치와 감정 표현을 바꿔서 만들어낸다. 반면, cross-identity motion transfer는 어떤 영상에서 말하는 사람에 대해 원본 영상에서 말하는 사람의 머리 위치와 감정 표현을 적용하는 것이다.  
</br>

![](./img/Face-Vid2Vid-10.jpg)

</br>

&nbsp; 둘째, face redirection이다. 원본 영상에서 말하는 사람의 감정 표현은 그대로 유지하되, 머리 위치를 바꾼 영상을 합성해내는 것이다. face redirection의 예로, 카메라에 말하는 사람의 얼굴의 정면이 보이게끔 하는 face frontalization이 있다.

</br>


&nbsp;  셋째, 

</br>

### 선행 연구의 한계
---
</br>



</br>

### Face-Vid2Vid
---
</br>


</br>

### Core Components of Face-Vid2Vid
---
</br>




</br>


### Technical details of Face-Vid2Vid
---

</br>


</br>


	
### 실험
---
</br>



</br>

### 논문의 한계 및 배울 점 
---
